{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9bde830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import graphviz as gr\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3dd3ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0): \n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a6c8b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim): #dim is dimension\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "106f27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    \n",
    "    if conf==False:\n",
    "        conf_mult = 0 \n",
    "    else:\n",
    "        conf_mult=1\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(2,1,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 \n",
    "    Y = (tau-conf_mult*C*0.1)*T+X@beta0+conf_mult*0.8*C+err\n",
    "    \n",
    "    if conf==False:     #if confounder=false, we only generate Y,T,X, otherwise, generate Y,T,X,C\n",
    "        return (Y,T,X) \n",
    "    else:\n",
    "        return (Y,T,X,C)\n",
    "    \n",
    "\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c460ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau=3\n",
    "N=1000\n",
    "p=1\n",
    "p0=1\n",
    "corr=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99aefd4",
   "metadata": {},
   "source": [
    "## 1. Simulate a DGP where the outcome of interest depends on a randomly assigned treatment andsome observed covariates. How does your estimate of the treatment effect parameter compare in the following two cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d299fe3f",
   "metadata": {},
   "source": [
    "-a.Data Generating Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ea12b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,T,X=fn_generate_data(tau,N,p,p0,corr,conf = False) #DGP#\n",
    "#Y is the outcome \n",
    "#T is the treatment allocation \n",
    "#X is the covariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a12a5d",
   "metadata": {},
   "source": [
    "-b.DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3c5affd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"134pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\r\n",
       "<!-- T -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>T</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\r\n",
       "</g>\r\n",
       "<!-- Y -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>Y</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\r\n",
       "</g>\r\n",
       "<!-- T&#45;&gt;Y -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>T&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.3496,-72.7646C39.7115,-64.2831 45.1469,-53.7144 50.0413,-44.1974\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.2346,-45.6409 54.6957,-35.1473 47.0096,-42.4395 53.2346,-45.6409\"/>\r\n",
       "</g>\r\n",
       "<!-- X -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>X</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\r\n",
       "</g>\r\n",
       "<!-- X&#45;&gt;Y -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>X&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.6504,-72.7646C86.2885,-64.2831 80.8531,-53.7144 75.9587,-44.1974\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.9904,-42.4395 71.3043,-35.1473 72.7654,-45.6409 78.9904,-42.4395\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2a7191d8df0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = gr.Digraph()\n",
    "g1.edge(\"T\", \"Y\")\n",
    "g1.edge(\"X\", \"Y\")\n",
    "g1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b245253",
   "metadata": {},
   "source": [
    "-c.Monte Carlo without controling covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "153a1291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3133.38it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 230.41it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {} #not control covariate\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data(tau,N,p,p0,corr,conf=False)\n",
    "        Yt = Y[np.where(T==1)[0],:]\n",
    "        Yc = Y[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b189f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.009785824002652191, RMSE=0.5285764854546036, size=0.059\n",
      "N=1000: bias=0.0018928133359914572, RMSE=0.15724121427307639, size=0.052\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad64256b",
   "metadata": {},
   "source": [
    "-d.Monte Carlo with controlling covariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "307be4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1544.91it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 182.46it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {} #control for covariate\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data(tau,N,p,p0,corr,conf=False)\n",
    "        covars = np.concatenate([T,X],axis = 1)\n",
    "        mod = sm.OLS(Y,sm.add_constant(covars))\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[1]\n",
    "        se_tauhat = res.HC1_se[1]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "70deb48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.004415168652520104, RMSE=0.19740025945322262, size=0.049\n",
      "N=1000: bias=-0.002136708943523738, RMSE=0.06494482255276045, size=0.058\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aafe2b",
   "metadata": {},
   "source": [
    "-e.\n",
    "One real life example of randomly assigned treatment could be medicine testing experiment. For example,in the expriment on the effect of covid vaccine, people are randomly assigned into two groups. People in the treatment group get real vaccine, but people in the control group get fake vaccine. After a few weeks or months, researchers will collect the infectious rate or death rate of covid in both groups, and check if there is significant difference between two groups. However, the treatment of real vaccine is not the only determinant here; ages might be another variables that researchers look on, since Covid might have a bigger healthy impact on senior people than young people. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36342e26",
   "metadata": {},
   "source": [
    "## 2. Simulate a DGP with a confounder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b335c95",
   "metadata": {},
   "source": [
    "-a.DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6d9ab0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,T,X,C=fn_generate_data(tau,N,p,p0,corr,conf = True)\n",
    "#Y is the outcome,\n",
    "#T is the treatment allocation\n",
    "#X is the covariate \n",
    "#C is the confounders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98039e5b",
   "metadata": {},
   "source": [
    "-b.DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "17cf85ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"134pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\r\n",
       "<!-- C -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>C</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">C</text>\r\n",
       "</g>\r\n",
       "<!-- Y -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>Y</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\r\n",
       "</g>\r\n",
       "<!-- C&#45;&gt;Y -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>C&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.4297,-74.8345C74.2501,-64.9376 60.4761,-51.5462 48.9694,-40.3591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.4055,-37.8461 41.7957,-33.3847 46.5259,-42.865 51.4055,-37.8461\"/>\r\n",
       "</g>\r\n",
       "<!-- T -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>T</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\r\n",
       "</g>\r\n",
       "<!-- C&#45;&gt;T -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>C&#45;&gt;T</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-71.6966C99,-63.9827 99,-54.7125 99,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-46.1043 99,-36.1043 95.5001,-46.1044 102.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- X -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>X</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\r\n",
       "</g>\r\n",
       "<!-- X&#45;&gt;Y -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>X&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-71.6966C27,-63.9827 27,-54.7125 27,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5001,-46.1043 27,-36.1043 23.5001,-46.1044 30.5001,-46.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2a7191e0490>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2 = gr.Digraph()\n",
    "g2.edge(\"C\", \"Y\")\n",
    "g2.edge(\"X\", \"Y\")\n",
    "g2.edge(\"C\", \"T\")\n",
    "g2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e5fe4",
   "metadata": {},
   "source": [
    "-c.Monte Carlo without control confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c4b45241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3202.07it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 238.61it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {} #not control covariate\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X,C = fn_generate_data(tau,N,p,p0,corr,conf=True)\n",
    "        Yt = Y[np.where(T==1)[0],:]\n",
    "        Yc = Y[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ba009610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.016421689992018693, RMSE=0.5772553248067815, size=0.052\n",
      "N=1000: bias=-0.003229156811613643, RMSE=0.18319173142207418, size=0.045\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb28f6c",
   "metadata": {},
   "source": [
    "-d.Monte Carlo with Controlling Confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "acd1f13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1613.07it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 184.33it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {} #control for covariate\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X,C = fn_generate_data(tau,N,p,p0,corr,conf=True)\n",
    "        covars = np.concatenate([T,X,C],axis = 1)\n",
    "        mod = sm.OLS(Y,sm.add_constant(covars))\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[1]\n",
    "        se_tauhat = res.HC1_se[1]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cb92edc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.01460184936301475, RMSE=0.20126556526190134, size=0.057\n",
      "N=1000: bias=-0.0031056593047888155, RMSE=0.06287424239693856, size=0.035\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddae44",
   "metadata": {},
   "source": [
    "-d.   A possible real life of example could be regular exercise. Let's assume that the treatment is randomly assigned milk from a NGO, and the outcome is the healthy body. Regular excercise can help absorbing the nutrition in the milk and thus indirectly makes one's body healthier. Regular excercise can also improve one's muscle strength, and thus directly make one's body healthier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a1f172",
   "metadata": {},
   "source": [
    "## 3. Simulate a DGP with selection bias into the treatment (variable in between the path from the treatment to the outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "55420793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data_sbias(tau,N,p,p0,corr,conf = True):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+1 # 1 confounder and variable for randomizing treatment\n",
    "    \n",
    "    if conf==False:\n",
    "        conf_mult = 0 \n",
    "    else:\n",
    "        conf_mult=1\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    C = allX[:,0].reshape([N,1]) # confounder\n",
    "    X = allX[:,1:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(2,1,[p,1])\n",
    "    Z = X+0.2*T\n",
    "    \n",
    "    beta0[p0:p] = 0 \n",
    "    Y = (tau-conf_mult*C*0.1)*T+Z@beta0+conf_mult*0.8*C+err\n",
    "    \n",
    "    if conf==False:     #if confounder=false, we only generate Y,T,X, otherwise, generate Y,T,X,C\n",
    "        return (Y,T,Z) \n",
    "    else:\n",
    "        return (Y,T,Z,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd575185",
   "metadata": {},
   "source": [
    "a.DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f13c263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,T,Z=fn_generate_data_sbias(tau,N,p,p0,corr,conf = False) #DGP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6796655",
   "metadata": {},
   "source": [
    "b.DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e9fd3efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"90pt\" height=\"188pt\"\r\n",
       " viewBox=\"0.00 0.00 90.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 86,-184 86,4 -4,4\"/>\r\n",
       "<!-- T -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>T</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\r\n",
       "</g>\r\n",
       "<!-- Y -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>Y</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\r\n",
       "</g>\r\n",
       "<!-- T&#45;&gt;Y -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>T&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M23.7517,-143.888C21.9542,-133.542 19.9053,-120.063 19,-108 17.8026,-92.0449 17.8026,-87.9551 19,-72 19.6366,-63.5179 20.8384,-54.3361 22.1208,-46.0356\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"25.5836,-46.5472 23.7517,-36.1119 18.6763,-45.412 25.5836,-46.5472\"/>\r\n",
       "</g>\r\n",
       "<!-- Z -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>Z</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"55\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Z</text>\r\n",
       "</g>\r\n",
       "<!-- T&#45;&gt;Z -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>T&#45;&gt;Z</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.6356,-144.411C36.9134,-136.216 40.9442,-126.14 44.6181,-116.955\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.9477,-118.055 48.412,-107.47 41.4484,-115.455 47.9477,-118.055\"/>\r\n",
       "</g>\r\n",
       "<!-- Z&#45;&gt;Y -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>Z&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.3644,-72.411C45.0866,-64.2164 41.0558,-54.1395 37.3819,-44.9548\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.5516,-43.4548 33.588,-35.4699 34.0523,-46.0546 40.5516,-43.4548\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2a7191df220>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g3 = gr.Digraph()\n",
    "g3.edge(\"T\", \"Y\")\n",
    "g3.edge(\"T\", \"Z\")\n",
    "g3.edge(\"Z\", \"Y\")\n",
    "g3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b12bc",
   "metadata": {},
   "source": [
    "c. Monte Carlo without control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fd62b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2954.05it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 230.71it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {} #not control covariate\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        fn_generate_data_sbias(tau,N,p,p0,corr,conf = False)\n",
    "        Yt = Y[np.where(T==1)[0],:]\n",
    "        Yc = Y[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "274db58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.30899682295084185, RMSE=0.3089968229508418, size=0.0\n",
      "N=1000: bias=0.30899682295084185, RMSE=0.3089968229508418, size=0.0\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce3e04",
   "metadata": {},
   "source": [
    "-d. Monte Carlo with Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b73caedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1697.56it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 176.64it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {} #control for covariate\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,Z=fn_generate_data_sbias(tau,N,p,p0,corr,conf = False)\n",
    "        covars = np.concatenate([T,Z],axis = 1)\n",
    "        mod = sm.OLS(Y,sm.add_constant(covars))\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[1]\n",
    "        se_tauhat = res.HC1_se[1]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f87ad3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.0010446184897130565, RMSE=0.1931639266135417, size=0.042\n",
      "N=1000: bias=0.0019825005110417136, RMSE=0.06419495945474434, size=0.05\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332582d",
   "metadata": {},
   "source": [
    "-e.A real life example could be the followings: Exercise is treatment; Healthy food is the selection bias; Healthy body is the outcome. Because one is trying to do excersie to get a fit body, he/she does not purchase junk food any more, and thus his/her body becomes healthier. This is the indirect approach with bias. The direct approach example could be that one do exercise, but this person does not control what he/she eats every day. He/she still has a healthy body because he/she does exercise everyday."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
